{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b4cebc6",
   "metadata": {},
   "source": [
    "# PyGEM MCMC calibration analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de58eff",
   "metadata": {},
   "source": [
    "Brandon Tober, David Rounce<br>\n",
    "Carnegie Mellon University<br>\n",
    "20241025<br><br>\n",
    "\n",
    "The main objective of this notebook is to assess the performance of MCMC calibration method for a given region. The analysis in this notebook assumes that three MCMC chains have been run for each glacier in Alaska, which we'll now assess.\n",
    "\n",
    "If the calibration has not yet been completed, first run 3 MCMC calibration chains - note, check option_use_emulator under the MCMC_params in ~/PyGEM/config.yaml.  If `option_use_emulator` is `true`, the calibration procedure must first have been completed with `option_calibration = emulator`.  Steps detailed below (if one does not wish to run MCMC calibration with the emulator and instead run the full model, set `option_use_emulator` to `false` and skip to step 3.):\n",
    "\n",
    "1. run_calibration -rgi_region01 1 -option_calibration emulator\n",
    "2. run_mcmc_priors -rgi_region01 1\n",
    "3. run_calibration -rgi_region01 1 -option_calibration MCMC -nchains 3\n",
    "\n",
    "See the *run_calibration.ipynb* Jupyter Notebook for further demonstration on MCMC calibration.\n",
    "\n",
    "Note, we've subset to run only glaciers with area > 1 sq. km to speed up processing. We will load the resulting MCMC calibration chains and assess the chain convergence (Gleman-Rubin statistic; Gelman and Rubin, 1992, https://doi.org/10.1214/ss/1177011136) and the effective sample size (number of independent samples) for each glacier. We seek a calibration that results chain convergence (Gelman-Rubin ~1) and an effective sample size of ~100+ for each glacier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ###\n",
    "import os, pickle, glob, copy, sys, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import arviz as az\n",
    "import xarray as xr\n",
    "import matplotlib.image as mpimg\n",
    "# pygem imports\n",
    "import pygem.setup.config as config\n",
    "# check for config\n",
    "config.ensure_config()\n",
    "# read the config\n",
    "pygem_prms = config.read_config()   # NOTE: ensure that your root path in ~/PyGEM/config.yaml points to\n",
    "                                    # the appropriate location. If any errors occur, check this first.\n",
    "import pygem.pygem_modelsetup as modelsetup\n",
    "from pygem import mcmc\n",
    "from pygem.shop import oib\n",
    "# set some plotting defaults\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48de5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output calibration path - 01 here indicates RGI region 1 (a.k.a. Alaska)\n",
    "datpath = pygem_prms['root']+'/Output/calibration/01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rgi table for all glaciers - this is used to get the area of each glacier to plot against\n",
    "rgi_glacs = modelsetup.selectglaciersrgitable(rgi_regionsO1=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cec50",
   "metadata": {},
   "source": [
    "In the cell below we'll loop through all output calibration json files, load the parameters for each chain, and run some diagnostic statistics (median, mean, standard deviation, interquartile range, minimum, maximum, effective sample size, and chain convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90be3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming we ran three chains, each output json calibration file will have \n",
    "# a key for each parameter pertaining to `chain_0`, `chain_1`, and `chain_2`\n",
    "chain_ns = [0,1,2]\n",
    "\n",
    "# keys (variables) of interest\n",
    "ks = ['kp','tbias','ddfsnow','ddfice','mb_mwea']\n",
    "\n",
    "# Define the list of functions - note, the chain convergence will be assessed separately using arviz.rhat()\n",
    "stats = [\n",
    "    lambda x: float(np.min(x)),\n",
    "    lambda x: float(np.max(x)),\n",
    "    lambda x: float(np.median(x)),\n",
    "    lambda x: float(np.mean(x)),\n",
    "    lambda x: float(np.std(x)),\n",
    "    lambda x: float(np.percentile(x, 75) - np.percentile(x, 25)), \n",
    "    mcmc.effective_n\n",
    "    ]\n",
    "# associated keys to use for each stat\n",
    "stats_ks = ['min','max','median','mean','std','iqr','n_eff']\n",
    "\n",
    "# create master mcmc_stats dictionary which will hold results of all glaciers\n",
    "mcmc_stats = {}\n",
    "# loop through all calibration files\n",
    "for f in sorted(glob.glob(datpath + '/*-modelprms_dict.json')):\n",
    "    try:\n",
    "        # get RGI glacier number\n",
    "        reg, glacno = f.split('/')[-1].split('.')[:2]\n",
    "        glacno = reg + '.' + glacno[:5]\n",
    "        # open json file\n",
    "        with open(f,'r') as fin:\n",
    "            # access MCMC key\n",
    "            prms_dict = json.load(fin)['MCMC']\n",
    "            # initialize stats dictionary for individual glacier\n",
    "            glac_stats = {}\n",
    "            # loop over variables\n",
    "            for k in ks:\n",
    "                # create key in glac_stats for variable which will also be a dictionary\n",
    "                glac_stats[k] = {}\n",
    "                # go through each chain and calculate some stats on each chain for each variable\n",
    "                for n in chain_ns:\n",
    "                    glac_stats[k][f'chain_{n}'] = {}\n",
    "                    # loop through each statistic\n",
    "                    for i, s in enumerate(stats_ks):\n",
    "                        glac_stats[k][f'chain_{n}'][s] = stats[i](prms_dict[k][f'chain_{n}'])\n",
    "\n",
    "                # calculate the gelman-rubin stat for each variable across all chains\n",
    "                # stack chains into a single 2d array which will be passed to arviz using the from_dict() method\n",
    "                chains = np.array([prms_dict[k][f'chain_{n}'] for n in chain_ns])\n",
    "                # convert the chains into an InferenceData object\n",
    "                idata = az.from_dict(posterior={k: chains})\n",
    "                # calculate the Gelman-Rubin statistic (rhat)\n",
    "                glac_stats[k]['rhat'] = float(az.rhat(idata).to_array().values[0])\n",
    "\n",
    "            # also assess the acceptance rate for each chain\n",
    "            glac_stats['ar'] = {}\n",
    "            for n in chain_ns:\n",
    "                glac_stats['ar'][f'chain_{n}'] = {}\n",
    "                # take 100-samle rolling average of the acceptance rate\n",
    "                rolling_ar = np.convolve(np.array(prms_dict['ar'][f'chain_{n}']), np.ones(100)/100, mode='valid')\n",
    "                # loop through each statistic\n",
    "                for i, s in enumerate(stats_ks[:-2]):\n",
    "                    glac_stats['ar'][f'chain_{n}'][s] = stats[i](rolling_ar)\n",
    "\n",
    "        # get glacier size\n",
    "        glac_stats['area'] = float(rgi_glacs.loc[rgi_glacs['glacno'] == glacno, 'Area'].iloc[0])\n",
    "        # store glac_stats within mcmc_glac_stats\n",
    "        mcmc_stats[glacno] = glac_stats\n",
    "    except Exception as err:\n",
    "        print(glacno, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93941c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's our regional MCMC stats dictionary look like?\n",
    "mcmc_stats[list(mcmc_stats.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bab84e",
   "metadata": {},
   "source": [
    "In the next cell we'll plot the Gelman-Rubin convergence metric for each glacier across each parameter, the glacierwide specific mass balance ($\\dot{B}$), precipitation factor ($k_p$), temperature bias ($T_{bias}$), and the degree-day factor of snow ($f_{snow}$), as well as the effective sample size, and the average acceptance rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure that has a column for the Gelman-Rubin as well as the effective sample size for each parameter, \n",
    "# and also plot the average acceptance rate across all chains\n",
    "\n",
    "# initialize the figure (4 rows, 3 columns)\n",
    "s=1\n",
    "fig = plt.figure(figsize=(5,6))\n",
    "gs = gridspec.GridSpec(4, 3, width_ratios=[1, 1, 1], height_ratios=[1, 1, 1, 1], figure=fig)\n",
    "\n",
    "# create subplots\n",
    "axes = []\n",
    "for i in range(4):\n",
    "    axes.append(fig.add_subplot(gs[i, 0]))  # left column, 4 rows\n",
    "for i in range(4):    \n",
    "    axes.append(fig.add_subplot(gs[i, 1]))  # middle column, 4 rows\n",
    "axes.append(fig.add_subplot(gs[0, 2]))      # top right panel\n",
    "\n",
    "# get each glacier's area - we'll use this as the xaxis\n",
    "xs = [mcmc_stats[g]['area'] for g in mcmc_stats.keys()]\n",
    "\n",
    "for i, k in enumerate(['mb_mwea','kp','tbias','ddfsnow']):\n",
    "    # plot gelman-rubin for each glacier\n",
    "    rhats = [mcmc_stats[g][k]['rhat'] for g in mcmc_stats.keys()]\n",
    "    axes[i].scatter(xs, rhats, c='k',s=s)\n",
    "\n",
    "    # plot average n_eff across all chains\n",
    "    n_effs = [np.nanmean([mcmc_stats[g][k][f'chain_{n}']['n_eff'] for n in [0,1,2]]) for g in mcmc_stats.keys()]\n",
    "    axes[i+4].scatter(xs, n_effs, c='k',s=s)\n",
    "\n",
    "    # get count where n_eff >=100\n",
    "    pct = int(round(100*(np.count_nonzero(np.asarray(n_effs)>=100)/len(n_effs))))\n",
    "    # annotate percentage\n",
    "    axes[i+4].plot([],[],label=f'{pct}%')\n",
    "    axes[i+4].legend(handlelength=0,fancybox=False, borderaxespad=0)\n",
    "    \n",
    "# plot average acceptance rate across all chains\n",
    "ars = [np.nanmean([mcmc_stats[g]['ar'][f'chain_{n}']['mean'] for n in [0,1,2]]) for g in mcmc_stats.keys()]\n",
    "axes[-1].scatter(xs, ars, c='k',s=s)\n",
    "\n",
    "# annotate total number of glaciers\n",
    "axes[0].plot([],[],label=f'N={len(mcmc_stats.keys())}')\n",
    "axes[0].legend(handlelength=0,fancybox=False, borderaxespad=0)\n",
    "\n",
    "# loop through all axes, add ticks on all sides\n",
    "for i,a in enumerate(axes):\n",
    "    a.xaxis.set_ticks_position('both')\n",
    "    a.yaxis.set_ticks_position('both')\n",
    "    a.tick_params(axis=\"both\",direction=\"inout\")\n",
    "    # make xaxis log-scale\n",
    "    a.set_xscale('log')\n",
    "    # set xmin as 1:max\n",
    "    a.set_xlim([1,a.get_xlim()[1]])\n",
    "    # remove xticklabels from middle panels not at the bottom of each column\n",
    "    if i not in [3,7,8]:\n",
    "        a.set_xticklabels([])\n",
    "    \n",
    "# manually set some ylimits\n",
    "for i,a in enumerate(axes):\n",
    "    if i<4:\n",
    "        a.set_ylim([0.99, 1.5])\n",
    "    if (i>4) & (i<8):\n",
    "        a.set_ylim([0, 750])\n",
    "    # if i==4:\n",
    "    #     a.set_ylim([0, 2000])\n",
    "\n",
    "axes[-1].set_ylim([0,axes[-1].get_ylim()[-1]])\n",
    "\n",
    "# set ylabels for each panel\n",
    "axes[0].set_ylabel(r'$\\hat{{R}}_{\\dot{{B}}}$')\n",
    "axes[1].set_ylabel(r'$\\hat{{R}}_{K_{p}}$')\n",
    "axes[2].set_ylabel(r'$\\hat{{R}}_{T_{bias}}$')\n",
    "axes[3].set_ylabel(r'$\\hat{{R}}_{fsnow}$')\n",
    "axes[4].set_ylabel(r'${n}_{\\dot{{B}}}$')\n",
    "axes[5].set_ylabel(r'${n}_{K_{p}}$')\n",
    "axes[6].set_ylabel(r'${n}_{T_{bias}}$')\n",
    "axes[7].set_ylabel(r'${n}_{fsnow}$')\n",
    "axes[-1].set_ylabel(r'${{ar}}$')\n",
    "# xaxis label\n",
    "fig.text(0.5, 0, r'Glacier Area (km$^2$)', va='center',ha='center')\n",
    "# figure title\n",
    "fig.text(0.5, 1, 'Alaska MCMC calibration', va='center',ha='center')\n",
    "plt.subplots_adjust(left=0.1, bottom=0.075, right=1, top=0.95, wspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff378f",
   "metadata": {},
   "source": [
    "Overall this looks pretty good - most glaciers have an effective sample size > 100 for each parameter, and chains seem to converge to ~1 for the most part. Some glaciers clearly have a higher Gelman-Rubin convergence metric than we'd like - let's plot all chains for these glaciers side-by-side to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all glaciers with r-hat > 1.1\n",
    "glacs_check = []\n",
    "glac_ns = list(mcmc_stats.keys())\n",
    "for i, k in enumerate(['mb_mwea','kp','tbias','ddfsnow']):\n",
    "    rhats = [mcmc_stats[g][k]['rhat'] for g in mcmc_stats.keys()]\n",
    "    mask = np.where(np.array(rhats)>1.1)[0]\n",
    "    for j in mask:\n",
    "        if glac_ns[j] not in glacs_check:\n",
    "            glacs_check.append(glac_ns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de21ff5",
   "metadata": {},
   "source": [
    "Plot all chains side-by-side so we can see if anything funny is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r'$\\hat{{R}}_{T_{bias}}$', r'$\\hat{{R}}_{K_{p}}$', r'$\\hat{{R}}_{fsnow}$', r'$\\hat{{R}}_{\\dot{{B}}}$']\n",
    "for g in glacs_check:\n",
    "    fig,ax=plt.subplots(ncols=3,figsize=(6.5,3.5))\n",
    "    for chain in [0,1,2]:\n",
    "        img = mpimg.imread(datpath + '/fig/' + f'{g}-chain{chain}.png')\n",
    "        ax[chain].imshow(img)\n",
    "        ax[chain].axis('off')  # Hide axis\n",
    "    fig.text(0.025,0.175,f'{g}, {round(mcmc_stats[g]['area'],2)} sq. km', fontsize=6)\n",
    "    # annotate r-hat for each variable at the bottom of the figure\n",
    "    for i, k in enumerate(['tbias','kp','ddfsnow','mb_mwea']):\n",
    "        fig.text(0.025,0.175-((i+1)*(0.04)),labels[i] + ' = ' +  str(round(mcmc_stats[g][k]['rhat'],1)),fontsize=6)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0.1, right=1, top=1.125, hspace=0, wspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4359566",
   "metadata": {},
   "source": [
    "Takeaways: There seem to be a couple different factors resulting in MCMC chains not converging for (predominantly small <10 sq. km) glaciers. <br>\n",
    "1. Some chains exhibit a bi- or multimodal behavior, where there are seemingly multiple modes of acceptible parameter spaces.\n",
    "2. Some chains just remain stuck and never accept a new step from the initial guess."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pygem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
